{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LUSw8f8Bk1U9uoeQtMPEq9ufk7UeOJuy","timestamp":1728117623786}],"authorship_tag":"ABX9TyOB+njrLhblsWp0pyuTxJ3A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJVC-Vpw1WL_","executionInfo":{"status":"ok","timestamp":1728117612108,"user_tz":-330,"elapsed":11650,"user":{"displayName":"Susmetha D","userId":"10699547492657345522"}},"outputId":"53c55d90-88ec-4b86-c62b-b1dff6c2b6f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Logistic Regression ---\n","Accuracy: 0.8155\n","Confusion Matrix:\n","[[1559   48]\n"," [ 321   72]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.97      0.89      1607\n","           1       0.60      0.18      0.28       393\n","\n","    accuracy                           0.82      2000\n","   macro avg       0.71      0.58      0.59      2000\n","weighted avg       0.78      0.82      0.77      2000\n","\n","\n","\n","--- Random Forest ---\n","Accuracy: 0.8645\n","Confusion Matrix:\n","[[1545   62]\n"," [ 209  184]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.96      0.92      1607\n","           1       0.75      0.47      0.58       393\n","\n","    accuracy                           0.86      2000\n","   macro avg       0.81      0.71      0.75      2000\n","weighted avg       0.85      0.86      0.85      2000\n","\n","\n","\n","--- Gradient Boosting ---\n","Accuracy: 0.8660\n","Confusion Matrix:\n","[[1547   60]\n"," [ 208  185]]\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.96      0.92      1607\n","           1       0.76      0.47      0.58       393\n","\n","    accuracy                           0.87      2000\n","   macro avg       0.82      0.72      0.75      2000\n","weighted avg       0.86      0.87      0.85      2000\n","\n","\n","\n"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Load the dataset\n","file_path = '/content/Churn_Modelling.csv'  # replace with the actual path if running on your local machine\n","data = pd.read_csv(file_path)\n","\n","# Dropping irrelevant columns\n","data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n","\n","# Encoding categorical variables\n","label_encoder = LabelEncoder()\n","data['Geography'] = label_encoder.fit_transform(data['Geography'])\n","data['Gender'] = label_encoder.fit_transform(data['Gender'])\n","\n","# Defining the feature matrix (X) and target vector (y)\n","X = data.drop('Exited', axis=1)\n","y = data['Exited']\n","\n","# Splitting the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardizing the feature matrix (since algorithms like Logistic Regression are sensitive to feature scaling)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Logistic Regression model\n","log_reg = LogisticRegression()\n","log_reg.fit(X_train, y_train)\n","y_pred_log_reg = log_reg.predict(X_test)\n","\n","# Random Forest model\n","random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n","random_forest.fit(X_train, y_train)\n","y_pred_rf = random_forest.predict(X_test)\n","\n","# Gradient Boosting model\n","gbc = GradientBoostingClassifier(n_estimators=100, random_state=42)\n","gbc.fit(X_train, y_train)\n","y_pred_gbc = gbc.predict(X_test)\n","\n","# Evaluating the models\n","def evaluate_model(y_test, y_pred, model_name):\n","    print(f\"--- {model_name} ---\")\n","    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n","    print(\"Confusion Matrix:\")\n","    print(confusion_matrix(y_test, y_pred))\n","    print(\"Classification Report:\")\n","    print(classification_report(y_test, y_pred))\n","    print(\"\\n\")\n","\n","# Evaluate each model\n","evaluate_model(y_test, y_pred_log_reg, \"Logistic Regression\")\n","evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n","evaluate_model(y_test, y_pred_gbc, \"Gradient Boosting\")\n"]}]}