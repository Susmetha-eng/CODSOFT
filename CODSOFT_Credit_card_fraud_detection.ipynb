{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the data\n",
        "train_data = pd.read_csv('/content/fraudTrain.csv')\n",
        "test_data = pd.read_csv('/content/fraudTest.csv')\n",
        "\n",
        "# Preprocessing\n",
        "# Dropping columns that won't be useful for the model like 'trans_date_trans_time' and 'merchant'\n",
        "train_data = train_data.drop(columns=['trans_date_trans_time', 'merchant', 'cc_num', 'first', 'last', 'street', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long'])\n",
        "test_data = test_data.drop(columns=['trans_date_trans_time', 'merchant', 'cc_num', 'first', 'last', 'street', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long'])\n",
        "\n",
        "# Handle missing values (drop rows with NaN in target)\n",
        "train_data = train_data.dropna(subset=['is_fraud'])\n",
        "\n",
        "# Split features and target\n",
        "X = train_data.drop(columns=['is_fraud'])\n",
        "y = train_data['is_fraud']\n",
        "\n",
        "# One-Hot Encoding for categorical variables\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Column transformer to handle both categorical encoding and scaling for numerical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), X.select_dtypes(include=['int64', 'float64']).columns),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. Logistic Regression Model Pipeline\n",
        "log_reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                   ('classifier', LogisticRegression(max_iter=1000))])\n",
        "log_reg_pipeline.fit(X_train, y_train)\n",
        "y_pred_log_reg = log_reg_pipeline.predict(X_val)\n",
        "\n",
        "# 2. Decision Tree Model Pipeline\n",
        "decision_tree_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                         ('classifier', DecisionTreeClassifier(random_state=42))])\n",
        "decision_tree_pipeline.fit(X_train, y_train)\n",
        "y_pred_tree = decision_tree_pipeline.predict(X_val)\n",
        "\n",
        "# 3. Random Forest Model Pipeline\n",
        "random_forest_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                         ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))])\n",
        "random_forest_pipeline.fit(X_train, y_train)\n",
        "y_pred_forest = random_forest_pipeline.predict(X_val)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate all models\n",
        "print(\"Logistic Regression:\", evaluate_model(y_val, y_pred_log_reg))\n",
        "print(\"Decision Tree:\", evaluate_model(y_val, y_pred_tree))\n",
        "print(\"Random Forest:\", evaluate_model(y_val, y_pred_forest))\n",
        "\n",
        "# Test on test_data (follow same preprocessing steps)\n",
        "X_test = test_data.drop(columns=['is_fraud'])\n",
        "y_test = test_data['is_fraud']\n",
        "\n",
        "# Predict on test data using the best model (Random Forest, in this case)\n",
        "y_pred_test_forest = random_forest_pipeline.predict(X_test)\n",
        "print(\"Test Set Random Forest Performance:\", evaluate_model(y_test, y_pred_test_forest))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQSkrDCff0ig",
        "outputId": "af8174b6-b7e2-4c3c-dd5a-62701f3405e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: (0.9928194011651538, 0.7659574468085106, 0.2748091603053435, 0.4044943820224719)\n",
            "Decision Tree: (0.9956984148489365, 0.7566539923954373, 0.7595419847328244, 0.758095238095238)\n",
            "Random Forest: (0.9971887278146593, 0.9735449735449735, 0.7022900763358778, 0.8159645232815964)\n",
            "Test Set Random Forest Performance: (0.9966295915741589, 0.66, 0.26153846153846155, 0.3746243739565943)\n"
          ]
        }
      ]
    }
  ]
}